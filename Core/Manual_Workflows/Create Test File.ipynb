{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe247ea4-86b6-48bb-be4b-ffca3fdb2f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install netcdf4\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import urllib.request\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from itertools import count\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf469ec7-4f0c-4855-8021-5226f29f67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_DIR = Path.cwd()\n",
    "CORE_DIR = THIS_DIR.parent\n",
    "SERVICES_DIR = CORE_DIR / \"LAMBDA\" / \"viz_functions\" / \"viz_publish_service\" / \"services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2269b-c746-4427-b2df-2186cd31238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(CORE_DIR / \"Manual_Workflows\" / \"helper_functions\"))\n",
    "from shared_functions import sql_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040224d7-f19b-4e30-86a3-c75bb557db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ec2-user/SageMaker/Secrets.env') as f:\n",
    "    for l in f.readlines():\n",
    "        if l.strip():\n",
    "            var, val = l.strip().split(\"=\", 1)\n",
    "            os.environ[var] = val.replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efbfeef-6835-4949-9785-4483aa753121",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_TO_RF_DF = {\n",
    "    \"alaska\": sql_to_dataframe(\"SELECT feature_id, rf_10_0 as streamflow FROM derived.recurrence_flows_ak ORDER BY feature_id\"),\n",
    "    \"conus\": sql_to_dataframe('''\n",
    "        SELECT \n",
    "            rf.feature_id, \n",
    "            CASE WHEN ch.public_fim_domain IS TRUE \n",
    "                THEN rf.rf_10_0_17c \n",
    "                ELSE 0.0 \n",
    "            END as streamflow\n",
    "        FROM derived.recurrence_flows_conus rf\n",
    "        LEFT JOIN derived.channels_conus ch on ch.feature_id = rf.feature_id\n",
    "        ORDER BY feature_id\n",
    "    '''),\n",
    "    \"hawaii\": sql_to_dataframe(\"SELECT feature_id, rf_10_0 as streamflow FROM derived.recurrence_flows_hi ORDER BY feature_id\"),\n",
    "    \"puertorico\": sql_to_dataframe(\"SELECT feature_id, rf_10_0 as streamflow FROM derived.recurrence_flows_prvi ORDER BY feature_id\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011ba36-ccff-4939-8cd4-79107e1b29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIGURATIONS = {\n",
    "    \"analysis_assim\": {\n",
    "        \"alaska\": [\"channel_rt\", \"forcing\"],\n",
    "        \"conus\": [\"channel_rt\", \"land\", \"forcing\", \"reservoir\"],\n",
    "        \"hawaii\": [\"channel_rt\", \"forcing\"],\n",
    "        \"puertorico\": [\"channel_rt\", \"forcing\"]\n",
    "    },\n",
    "    \"medium_range\": {\n",
    "        \"alaska\": [\"channel_rt\", \"forcing\"],\n",
    "        \"conus\": [\"channel_rt\", \"forcing\", \"reservoir\"],\n",
    "    },\n",
    "    \"medium_range_blend\": {\n",
    "        \"alaska\": [\"channel_rt\", \"forcing\"],\n",
    "        \"conus\": [\"channel_rt\", \"forcing\"],\n",
    "        \"alaska\": [\"channel_rt\"],\n",
    "        \"conus\": [\"channel_rt\"],\n",
    "    },\n",
    "    \"short_range\": {\n",
    "        \"alaska\": [\"channel_rt\", \"forcing\"],\n",
    "        \"conus\": [\"channel_rt\", \"forcing\", \"reservoir\"],\n",
    "        \"hawaii\": [\"channel_rt\", \"forcing\"],\n",
    "        \"puertorico\": [\"channel_rt\", \"forcing\"]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb3516-07a1-408f-a969-42059f0bd7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_COUNTER = count(0)\n",
    "for MODEL, DOMAINS in DATASET_CONFIGURATIONS.items():\n",
    "    print(\"***********************\")\n",
    "    model_count = next(MODEL_COUNTER)\n",
    "    print(f\"MODEL: {MODEL} (count: {model_count})\")\n",
    "    for DOMAIN, PEs in DOMAINS.items():\n",
    "        print(f\"... DOMAIN: {DOMAIN}\")\n",
    "        for PE in PEs:\n",
    "            print(f\"...... PE: {PE}\")\n",
    "            CONFIG = (\"forcing_\" if PE == \"forcing\" else \"\") + MODEL + (f\"_{DOMAIN}\" if DOMAIN != \"conus\" else \"\") + (\"_mem1\" if MODEL == \"medium_range\" and PE != \"forcing\" else \"\")\n",
    "            S3 = boto3.client(\"s3\")\n",
    "            TIME_TAG = \"tm\" if \"analysis\" in MODEL else \"f\"\n",
    "            HOUR = \"00\"\n",
    "            if MODEL == \"analysis_assim\":\n",
    "                START_STEP = 0\n",
    "                END_STEP = 0\n",
    "                STEP = 1\n",
    "                STEP_FORMAT = \"%02d\"\n",
    "                if DOMAIN == \"hawaii\":\n",
    "                    if PE == \"channel_rt\":\n",
    "                        STEP_FORMAT = \"%04d\"\n",
    "                    elif PE == \"forcing\":\n",
    "                        STEP_FORMAT = \"%02d\"\n",
    "            elif MODEL == \"short_range\":\n",
    "                START_STEP = 1\n",
    "                END_STEP = 18\n",
    "                STEP = 1\n",
    "                STEP_FORMAT = \"%03d\"\n",
    "                if DOMAIN == \"alaska\":\n",
    "                    END_STEP = 15\n",
    "                elif DOMAIN == \"puertorico\":\n",
    "                    HOUR = \"06\"\n",
    "                    START_STEP = 1\n",
    "                    END_STEP = 48\n",
    "                    STEP = 1\n",
    "                    STEP_FORMAT = \"%03d\"\n",
    "                elif DOMAIN == \"hawaii\":\n",
    "                    if PE == \"forcing\":\n",
    "                        START_STEP = 1\n",
    "                        END_STEP = 48\n",
    "                        STEP = 1\n",
    "                        STEP_FORMAT = \"%03d\"\n",
    "                    else:\n",
    "                        START_STEP = 100\n",
    "                        END_STEP = 4800\n",
    "                        STEP = 100\n",
    "                        STEP_FORMAT = \"%05d\"\n",
    "            elif MODEL == \"medium_range\":\n",
    "                END_STEP = 240\n",
    "                START_STEP = 1\n",
    "                STEP_FORMAT = \"%03d\"\n",
    "\n",
    "            if 'forcing' in CONFIG:\n",
    "                INTEREST_VARS = ['RAINRATE']\n",
    "            elif 'coastal' in CONFIG:\n",
    "                INTEREST_VARS = ['elevation']\n",
    "            elif PE == 'land':\n",
    "                INTEREST_VARS = ['SNEQV', 'SNOWH', 'SOILICE', 'SOILSAT_TOP']\n",
    "            elif PE == 'channel_rt':\n",
    "                INTEREST_VARS = ['streamflow']\n",
    "            elif PE == 'reservoir':\n",
    "                INTEREST_VARS = ['water_sfc_elev']\n",
    "            else:\n",
    "                raise Exception(f\"Unknown PE: {PE}\")\n",
    "\n",
    "            PE += (\"_1\" if MODEL == \"medium_range\" and PE != \"forcing\" else \"\")\n",
    "            FNAME_TEMPLATE = f\"nwm.t{HOUR}z.{MODEL}.{PE}.{TIME_TAG}{{FILE_COUNT}}.{DOMAIN}.nc\"\n",
    "            FNAMES = [FNAME_TEMPLATE.format(FILE_COUNT=STEP_FORMAT % x) for x in range(START_STEP, END_STEP + (STEP * 1), STEP)]\n",
    "            DATE = datetime(datetime.now().year, datetime.now().month, datetime.now().day - 1).strftime('%Y%m%d')\n",
    "            URL_TEMPLATE = f\"https://nomads.ncep.noaa.gov/pub/data/nccf/com/nwm/prod/nwm.{DATE}/{CONFIG}/{{FNAME}}\"\n",
    "            DEST_BUCKET = \"hydrovis-ti-deployment-us-east-1\"\n",
    "            DEST_KEY = f\"test_nwm_outputs/{CONFIG}/{{FNAME}}\"\n",
    "\n",
    "            for fname in FNAMES:\n",
    "                ds = None\n",
    "                url = URL_TEMPLATE.format(FNAME=fname)\n",
    "                dest_key = DEST_KEY.format(FNAME=fname)\n",
    "                # print(f\"Downloading {url}...\")\n",
    "                urllib.request.urlretrieve(url, fname)\n",
    "                # print(f\"Opening {fname} with xarray...\")\n",
    "                with xr.open_dataset(fname) as ds:\n",
    "                    for interest_var in INTEREST_VARS:\n",
    "                        # print(f\"Applying apocalyptic values to {interest_var} variable...\")\n",
    "                        if interest_var == \"streamflow\":\n",
    "                            # print(\"Streamflow values before:\")\n",
    "                            # print(ds[interest_var].values)\n",
    "                            rf_df = DOMAIN_TO_RF_DF[DOMAIN]\n",
    "                            new_values = rf_df['streamflow'].values.copy()\n",
    "                            if DOMAIN == \"alaska\":\n",
    "                                new_values = np.concatenate(([100.0]*6, new_values))\n",
    "                            elif DOMAIN == \"hawaii\":\n",
    "                                new_values = np.concatenate((new_values, [100.0]*341))\n",
    "                            ds[interest_var].values = new_values\n",
    "                            # print(\"Streamflow values after:\")\n",
    "                            if DOMAIN == \"conus\":\n",
    "                                ds[interest_var].values[model_count::4] = 0\n",
    "                                # print(ds[interest_var].values)\n",
    "                            # else:\n",
    "                            #     print(ds[interest_var].values)\n",
    "                        else:\n",
    "                            ds[interest_var] = (ds[interest_var] + 1) * 100\n",
    "                    # print(\"Writing new dataset to tmp.nc...\")\n",
    "                    ds.to_netcdf('tmp.nc')\n",
    "                # print(f\"Uploading tmp.nc to s3://{DEST_BUCKET}/{dest_key}...\")\n",
    "                S3.upload_file('tmp.nc', DEST_BUCKET, dest_key)\n",
    "                # print(\"Removing iteration files...\")\n",
    "                os.remove('tmp.nc')\n",
    "                os.remove(fname)\n",
    "                \n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66448e-6651-4580-9465-3c87f3b2c2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
